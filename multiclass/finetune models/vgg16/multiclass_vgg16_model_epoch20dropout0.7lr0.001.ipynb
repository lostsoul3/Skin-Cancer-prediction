{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Lambda\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils,to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "import csv\n",
    "import cv2\n",
    "import scipy\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "epochs = 20\n",
    "# BASE_PATH = '/home/ec2-user/cell_classifier/'\n",
    "BASE_DIR = '../'\n",
    "batch_size = 32\n",
    "dropout = 0.7\n",
    "learning_rate = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for wbc_type in os.listdir(folder):\n",
    "        if not wbc_type.startswith('.'):\n",
    "            for image_filename in os.listdir(folder + wbc_type):\n",
    "                img_file = cv2.imread(folder + wbc_type + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    img_file = scipy.misc.imresize(arr=img_file, size=(120, 160, 3))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(wbc_type)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/misc/pilutil.py:480: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/misc/pilutil.py:483: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_data(BASE_DIR + 'images/TRAIN/')\n",
    "X_test, y_test = get_data(BASE_DIR + 'images/TEST/')\n",
    "#X_test_simple, y_test_simple = get_data(BASE_DIR + 'images/TEST_SIMPLE/')\n",
    "\n",
    "\n",
    "#X_train = X_train * 1./255.\n",
    "#X_test = X_test * 1./255.\n",
    "#X_test_simple = X_test_simple * 1./255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "y_train = np_utils.to_categorical(encoder.transform(y_train))\n",
    "y_test = np_utils.to_categorical(encoder.transform(y_test))\n",
    "#y_test_simple = np_utils.to_categorical(encoder.transform(y_test_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, base_model):\n",
    "\n",
    "    # get layers and add average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # add fully-connected layer\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "\n",
    "    # add output layer\n",
    "    predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # freeze pre-trained model area's layer\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # update the weight that are added\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # choose the layers which are updated by training\n",
    "    layer_num = len(model.layers)\n",
    "    for layer in model.layers[:int(layer_num * 0.9)]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in model.layers[int(layer_num * 0.9):]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # update the weights\n",
    "    model.compile(optimizer=SGD(lr=learning_rate, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=epochs)\n",
    "    return history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "9957/9957 [==============================] - 142s - loss: 2.2736   \n",
      "Epoch 1/20\n",
      "9957/9957 [==============================] - 123s - loss: 0.5788 - acc: 0.7713   \n",
      "Epoch 2/20\n",
      "9957/9957 [==============================] - 126s - loss: 0.4716 - acc: 0.8127   \n",
      "Epoch 3/20\n",
      "9957/9957 [==============================] - 139s - loss: 0.3939 - acc: 0.8491   \n",
      "Epoch 4/20\n",
      "9957/9957 [==============================] - 136s - loss: 0.3548 - acc: 0.8675   \n",
      "Epoch 5/20\n",
      "9957/9957 [==============================] - 148s - loss: 0.3191 - acc: 0.8805   \n",
      "Epoch 6/20\n",
      "9957/9957 [==============================] - 142s - loss: 0.2748 - acc: 0.9018   \n",
      "Epoch 7/20\n",
      "9957/9957 [==============================] - 148s - loss: 0.2557 - acc: 0.9034   \n",
      "Epoch 8/20\n",
      "9957/9957 [==============================] - 149s - loss: 0.2293 - acc: 0.9171   \n",
      "Epoch 9/20\n",
      "9957/9957 [==============================] - 149s - loss: 0.2073 - acc: 0.9263   \n",
      "Epoch 10/20\n",
      "9957/9957 [==============================] - 144s - loss: 0.1876 - acc: 0.9329   \n",
      "Epoch 11/20\n",
      "9957/9957 [==============================] - 150s - loss: 0.1546 - acc: 0.9486   \n",
      "Epoch 12/20\n",
      "9957/9957 [==============================] - 151s - loss: 0.1499 - acc: 0.9511   \n",
      "Epoch 13/20\n",
      "9957/9957 [==============================] - 149s - loss: 0.1317 - acc: 0.9578   \n",
      "Epoch 14/20\n",
      "9957/9957 [==============================] - 143s - loss: 0.1148 - acc: 0.9660   \n",
      "Epoch 15/20\n",
      "9957/9957 [==============================] - 154s - loss: 0.0980 - acc: 0.9726   \n",
      "Epoch 16/20\n",
      "9957/9957 [==============================] - 147s - loss: 0.0948 - acc: 0.9729   \n",
      "Epoch 17/20\n",
      "9957/9957 [==============================] - 150s - loss: 0.0914 - acc: 0.9752   \n",
      "Epoch 18/20\n",
      "9957/9957 [==============================] - 151s - loss: 0.0786 - acc: 0.9788   \n",
      "Epoch 19/20\n",
      "9957/9957 [==============================] - 156s - loss: 0.0671 - acc: 0.9844   \n",
      "Epoch 20/20\n",
      "9957/9957 [==============================] - 149s - loss: 0.0623 - acc: 0.9853   \n",
      "Predicting on test data\n"
     ]
    }
   ],
   "source": [
    "history = model(X_train, y_train, vgg_16_model)\n",
    "print('Predicting on test data')\n",
    "y_pred = np.rint(history.model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43063932448733416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.save_weights('multiclass_vgg16_model_epoch'+str(epochs)+'dropout'+str(dropout)+'lr'+str(learning_rate)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.load_weights('multiclass_vgg16_model_epoch'+str(epochs)+'dropout'+str(dropout)+'lr'+str(learning_rate)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 14,979,396\n",
      "Trainable params: 264,708\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[390  24  44 165]\n",
      " [248 182  85 105]\n",
      " [276  38 165 141]\n",
      " [205  50  17 352]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_unencoded = np.argmax(y_pred, axis=1)\n",
    "y_test_unencoded = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(confusion_matrix(y_test_unencoded, y_pred_unencoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
