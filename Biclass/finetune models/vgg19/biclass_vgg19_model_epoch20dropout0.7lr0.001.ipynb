{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential , Model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Lambda\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils , to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import csv\n",
    "import cv2\n",
    "import scipy\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "epochs = 20\n",
    "# BASE_PATH = '/home/ec2-user/cell_classifier/'\n",
    "BASE_DIR = '../'\n",
    "batch_size = 32\n",
    "dropout = 0.7\n",
    "learning_rate = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder):\n",
    "    \"\"\"\n",
    "    Load the data and labels from the given folder.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for wbc_type in os.listdir(folder):\n",
    "        if not wbc_type.startswith('.'):\n",
    "            if wbc_type in ['NEUTROPHIL', 'EOSINOPHIL']:\n",
    "                label = 'POLYNUCLEAR'\n",
    "            else:\n",
    "                label = 'MONONUCLEAR'\n",
    "            for image_filename in os.listdir(folder + wbc_type):\n",
    "                img_file = cv2.imread(folder + wbc_type + '/' + image_filename)\n",
    "                if img_file is not None:\n",
    "                    # Downsample the image to 120, 160, 3\n",
    "                    img_file = scipy.misc.imresize(arr=img_file, size=(120, 160, 3))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(label)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/misc/pilutil.py:480: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/misc/pilutil.py:483: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POLYNUCLEAR' 'POLYNUCLEAR' 'POLYNUCLEAR' ... 'MONONUCLEAR' 'MONONUCLEAR'\n",
      " 'MONONUCLEAR']\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_data(BASE_DIR + 'images/TRAIN/')\n",
    "print(y_train)\n",
    "X_test, y_test = get_data(BASE_DIR + 'images/TEST/')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_train, y_train, base_model):\n",
    "\n",
    "    # get layers and add average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # add fully-connected layer\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "\n",
    "    # add output layer\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # freeze pre-trained model area's layer\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # update the weight that are added\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # choose the layers which are updated by training\n",
    "    layer_num = len(model.layers)\n",
    "    for layer in model.layers[:int(layer_num * 0.9)]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in model.layers[int(layer_num * 0.9):]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # update the weights\n",
    "    model.compile(optimizer=SGD(lr=learning_rate, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=epochs)\n",
    "    return history\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_19_model = VGG19(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "9957/9957 [==============================] - 157s - loss: 7.9358   \n",
      "Epoch 1/20\n",
      "9957/9957 [==============================] - 154s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 2/20\n",
      "9957/9957 [==============================] - 162s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 3/20\n",
      "9957/9957 [==============================] - 168s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 4/20\n",
      "9957/9957 [==============================] - 180s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 5/20\n",
      "9957/9957 [==============================] - 174s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 6/20\n",
      "9957/9957 [==============================] - 171s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 7/20\n",
      "9957/9957 [==============================] - 179s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 8/20\n",
      "9957/9957 [==============================] - 174s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 9/20\n",
      "9957/9957 [==============================] - 193s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 10/20\n",
      "9957/9957 [==============================] - 193s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 11/20\n",
      "9957/9957 [==============================] - 192s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 12/20\n",
      "9957/9957 [==============================] - 199s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 13/20\n",
      "9957/9957 [==============================] - 200s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 14/20\n",
      "9957/9957 [==============================] - 205s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 15/20\n",
      "9957/9957 [==============================] - 206s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 16/20\n",
      "9957/9957 [==============================] - 186s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 17/20\n",
      "9957/9957 [==============================] - 198s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 18/20\n",
      "9957/9957 [==============================] - 201s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 19/20\n",
      "9957/9957 [==============================] - 196s - loss: 7.9432 - acc: 0.5018   \n",
      "Epoch 20/20\n",
      "9957/9957 [==============================] - 194s - loss: 7.9432 - acc: 0.5018   \n"
     ]
    }
   ],
   "source": [
    "history = model(X_train, y_train, vgg_19_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data\n",
      "0.5014073180538802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Predicting on test data')\n",
    "y_pred = np.rint(history.model.predict(X_test))\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.save_weights('biclass_vgg19_model_epoch'+str(epochs)+'dropout'+str(dropout)+'lr'+str(learning_rate)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.load_weights('biclass_vgg19_model_epoch'+str(epochs)+'dropout'+str(dropout)+'lr'+str(learning_rate)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 20,287,553\n",
      "Trainable params: 263,169\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1240]\n",
      " [   0 1247]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
